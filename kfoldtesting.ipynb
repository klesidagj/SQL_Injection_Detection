{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_metrics_and_confusion(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='binary')\n",
    "    recall = recall_score(y_true, y_pred, average='binary')\n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"confusion_matrix\": conf_matrix\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Fold 1 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klesi/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19514d4ea2649fd90c7b8f60fd264e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24735 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e0c9eab37c419e9225df860afd64e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klesi/Library/Python/3.9/lib/python/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/kk/by7jm7pj16g5h4227vd0p03m0000gn/T/ipykernel_20121/1707763636.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee5d4cfe7284a16b44513561040b1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0335, 'grad_norm': 0.0059939115308225155, 'learning_rate': 1.56877964639931e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6ebc147d34442b8571be0305fa103a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.010097723454236984, 'eval_accuracy': 0.9977360931435963, 'eval_f1': 0.996919014084507, 'eval_precision': 0.9991177767975298, 'eval_recall': 0.994729907773386, 'eval_runtime': 54.4129, 'eval_samples_per_second': 113.65, 'eval_steps_per_second': 3.565, 'epoch': 1.0}\n",
      "{'loss': 0.0072, 'grad_norm': 0.004320244770497084, 'learning_rate': 1.1375592927986202e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0035, 'grad_norm': 0.016220878809690475, 'learning_rate': 7.0633893919793015e-06, 'epoch': 1.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34646d584bf4e3fa04e6ff88d52babf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.007303901482373476, 'eval_accuracy': 0.9988680465717982, 'eval_f1': 0.9984632272228321, 'eval_precision': 0.9982440737489026, 'eval_recall': 0.9986824769433466, 'eval_runtime': 55.0216, 'eval_samples_per_second': 112.392, 'eval_steps_per_second': 3.526, 'epoch': 2.0}\n",
      "{'loss': 0.0021, 'grad_norm': 0.003098023124039173, 'learning_rate': 2.751185855972402e-06, 'epoch': 2.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f4c414c9ec47e296f10a37e9e894f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.007065522484481335, 'eval_accuracy': 0.9988680465717982, 'eval_f1': 0.9984605234220365, 'eval_precision': 1.0, 'eval_recall': 0.9969257795344751, 'eval_runtime': 83.8929, 'eval_samples_per_second': 73.713, 'eval_steps_per_second': 2.312, 'epoch': 3.0}\n",
      "{'train_runtime': 19963.2213, 'train_samples_per_second': 3.717, 'train_steps_per_second': 0.116, 'train_loss': 0.010026165740841574, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93239061d3e1472e818af37ab7f50d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting BERT embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 773/773 [05:32<00:00,  2.32it/s]\n",
      "Extracting BERT embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 194/194 [01:19<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m194/194\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klesi/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [23:32:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Fold 2 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/klesi/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644f2f825c304f21843510e4516b5060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24735 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87d5f2f276240439d5bfdd9391adf4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klesi/Library/Python/3.9/lib/python/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/kk/by7jm7pj16g5h4227vd0p03m0000gn/T/ipykernel_20121/1707763636.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c681593231149fea2720e751baeac74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.038, 'grad_norm': 0.01580238528549671, 'learning_rate': 1.56877964639931e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272e865c42044de1a068613c6f098fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.010422557592391968, 'eval_accuracy': 0.9978978007761966, 'eval_f1': 0.997143484948363, 'eval_precision': 0.9978012313104662, 'eval_recall': 0.9964866051822574, 'eval_runtime': 53.517, 'eval_samples_per_second': 115.552, 'eval_steps_per_second': 3.625, 'epoch': 1.0}\n",
      "{'loss': 0.005, 'grad_norm': 0.004091506823897362, 'learning_rate': 1.1375592927986202e-05, 'epoch': 1.29}\n",
      "{'loss': 0.005, 'grad_norm': 0.005149351432919502, 'learning_rate': 7.0633893919793015e-06, 'epoch': 1.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380219a48f8c4082bcf7bc8126c12bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.007773985154926777, 'eval_accuracy': 0.9985446313065977, 'eval_f1': 0.9980241492864984, 'eval_precision': 0.9978050921861282, 'eval_recall': 0.9982433025911287, 'eval_runtime': 8227.3979, 'eval_samples_per_second': 0.752, 'eval_steps_per_second': 0.024, 'epoch': 2.0}\n",
      "{'loss': 0.0004, 'grad_norm': 0.0007607076549902558, 'learning_rate': 2.751185855972402e-06, 'epoch': 2.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62b8a8bf0ee42b5a3406d92dd7d8c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.008957461453974247, 'eval_accuracy': 0.9987063389391979, 'eval_f1': 0.9982433025911287, 'eval_precision': 0.9982433025911287, 'eval_recall': 0.9982433025911287, 'eval_runtime': 54.6817, 'eval_samples_per_second': 113.091, 'eval_steps_per_second': 3.548, 'epoch': 3.0}\n",
      "{'train_runtime': 59494.1322, 'train_samples_per_second': 1.247, 'train_steps_per_second': 0.039, 'train_loss': 0.010740239740240517, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893c752909444be9b32f1e83b3f5f716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting BERT embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 773/773 [05:15<00:00,  2.45it/s]\n",
      "Extracting BERT embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 194/194 [01:22<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m194/194\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klesi/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [16:15:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Fold 3 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/klesi/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72ec6bacf914f4da03b7f96720b7174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24735 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f4fda7b96742b3bc74e6c21b0ad8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klesi/Library/Python/3.9/lib/python/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/kk/by7jm7pj16g5h4227vd0p03m0000gn/T/ipykernel_20121/1707763636.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163bd296f8ba418b88098a78b848d641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0343, 'grad_norm': 0.10693015158176422, 'learning_rate': 1.56877964639931e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5431a7b1ef642518846aa8e84a4e034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.008192090317606926, 'eval_accuracy': 0.9985446313065977, 'eval_f1': 0.99801893022232, 'eval_precision': 1.0, 'eval_recall': 0.9960456942003515, 'eval_runtime': 55.6924, 'eval_samples_per_second': 111.038, 'eval_steps_per_second': 3.483, 'epoch': 1.0}\n",
      "{'loss': 0.0067, 'grad_norm': 0.004905134905129671, 'learning_rate': 1.1375592927986202e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0041, 'grad_norm': 0.0019086517859250307, 'learning_rate': 7.0633893919793015e-06, 'epoch': 1.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d715ba96325435e8e8b0aa4e295958d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.005054842680692673, 'eval_accuracy': 0.9990297542043984, 'eval_f1': 0.9986813186813187, 'eval_precision': 0.9991204925241864, 'eval_recall': 0.9982425307557118, 'eval_runtime': 55.5588, 'eval_samples_per_second': 111.306, 'eval_steps_per_second': 3.492, 'epoch': 2.0}\n",
      "{'loss': 0.0024, 'grad_norm': 0.0012454116949811578, 'learning_rate': 2.751185855972402e-06, 'epoch': 2.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49acb484b5eb4535b98e50050ba49668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0060277520678937435, 'eval_accuracy': 0.9990297542043984, 'eval_f1': 0.9986807387862797, 'eval_precision': 0.9995598591549296, 'eval_recall': 0.9978031634446397, 'eval_runtime': 56.091, 'eval_samples_per_second': 110.249, 'eval_steps_per_second': 3.459, 'epoch': 3.0}\n",
      "{'train_runtime': 2484.0816, 'train_samples_per_second': 29.872, 'train_steps_per_second': 0.934, 'train_loss': 0.010271732032350447, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e3158cfb214c1ca21d484fe183a0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting BERT embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 773/773 [05:13<00:00,  2.46it/s]\n",
      "Extracting BERT embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 194/194 [01:17<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m194/194\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klesi/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [17:04:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Fold 4 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/klesi/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdde7d0be5464fcd91460fc6a2ed8aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24735 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e775e88c8534596bd150ffebed3f9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klesi/Library/Python/3.9/lib/python/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/kk/by7jm7pj16g5h4227vd0p03m0000gn/T/ipykernel_20121/1707763636.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40663c957a74a179f5c73d579b1f2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0366, 'grad_norm': 0.03838815912604332, 'learning_rate': 1.56877964639931e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220b128260af44358c0d02cb1f5d7481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.007240690290927887, 'eval_accuracy': 0.9983829236739974, 'eval_f1': 0.9978002639683238, 'eval_precision': 0.9991189427312775, 'eval_recall': 0.9964850615114236, 'eval_runtime': 52.5733, 'eval_samples_per_second': 117.626, 'eval_steps_per_second': 3.69, 'epoch': 1.0}\n",
      "{'loss': 0.0072, 'grad_norm': 0.0029470818117260933, 'learning_rate': 1.1375592927986202e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0045, 'grad_norm': 0.0021634851582348347, 'learning_rate': 7.0633893919793015e-06, 'epoch': 1.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f41a1579a54480b2e5e674e3975f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.003248423570767045, 'eval_accuracy': 0.999353169469599, 'eval_f1': 0.9991204925241864, 'eval_precision': 1.0, 'eval_recall': 0.9982425307557118, 'eval_runtime': 49.019, 'eval_samples_per_second': 126.155, 'eval_steps_per_second': 3.958, 'epoch': 2.0}\n",
      "{'loss': 0.0014, 'grad_norm': 0.0015587805537506938, 'learning_rate': 2.751185855972402e-06, 'epoch': 2.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994da634da45483b8e33b9bdc6d6b7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0035702846944332123, 'eval_accuracy': 0.9991914618369987, 'eval_f1': 0.9989008573312816, 'eval_precision': 0.9995600527936648, 'eval_recall': 0.9982425307557118, 'eval_runtime': 48.6332, 'eval_samples_per_second': 127.156, 'eval_steps_per_second': 3.989, 'epoch': 3.0}\n",
      "{'train_runtime': 2870.1879, 'train_samples_per_second': 25.854, 'train_steps_per_second': 0.808, 'train_loss': 0.01103257608598756, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae94f9a1e88845eca215a8987401480d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting BERT embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 773/773 [05:22<00:00,  2.40it/s]\n",
      "Extracting BERT embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 194/194 [01:21<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m194/194\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klesi/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [18:00:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ª Fold 5 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/klesi/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b39cb0e24ad4a95a84f46e00dbe77b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24736 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f814e1848e0d4af4a60509058ae5d26e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6183 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klesi/Library/Python/3.9/lib/python/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/kk/by7jm7pj16g5h4227vd0p03m0000gn/T/ipykernel_20121/1707763636.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994287c993294569bf9dcf28b92d2dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0338, 'grad_norm': 0.006256506312638521, 'learning_rate': 1.56877964639931e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1545e27453489e9ea0dcb7cf11cf69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.009346290491521358, 'eval_accuracy': 0.9985443959243085, 'eval_f1': 0.9980232813529542, 'eval_precision': 0.9978041282389108, 'eval_recall': 0.9982425307557118, 'eval_runtime': 55.7583, 'eval_samples_per_second': 110.889, 'eval_steps_per_second': 3.479, 'epoch': 1.0}\n",
      "{'loss': 0.0079, 'grad_norm': 0.8421815633773804, 'learning_rate': 1.1375592927986202e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0051, 'grad_norm': 0.007097525522112846, 'learning_rate': 7.0633893919793015e-06, 'epoch': 1.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3294716c52ba43a0aabb1122fc3ec202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.005664704367518425, 'eval_accuracy': 0.9990295972828724, 'eval_f1': 0.9986813186813187, 'eval_precision': 0.9991204925241864, 'eval_recall': 0.9982425307557118, 'eval_runtime': 139.013, 'eval_samples_per_second': 44.478, 'eval_steps_per_second': 1.396, 'epoch': 2.0}\n",
      "{'loss': 0.0024, 'grad_norm': 0.002093676710501313, 'learning_rate': 2.751185855972402e-06, 'epoch': 2.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61022581ce5140f5b17117c38d7d1d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00693671265617013, 'eval_accuracy': 0.9988678634966844, 'eval_f1': 0.998461876510657, 'eval_precision': 0.9986813186813187, 'eval_recall': 0.9982425307557118, 'eval_runtime': 72.4961, 'eval_samples_per_second': 85.287, 'eval_steps_per_second': 2.676, 'epoch': 3.0}\n",
      "{'train_runtime': 4754.4852, 'train_samples_per_second': 15.608, 'train_steps_per_second': 0.488, 'train_loss': 0.010721478407215383, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a28ddcb6ad4ac48a473a3712b9a798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting BERT embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 773/773 [07:09<00:00,  1.80it/s]  \n",
      "Extracting BERT embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 194/194 [01:25<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m194/194\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klesi/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [19:29:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"/Users/klesi/Documents/Modified_SQL_Dataset.csv\")\n",
    "\n",
    "# Set up Stratified K-Fold\n",
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Track metrics\n",
    "codebert_scores = []\n",
    "dnn_scores = []\n",
    "xgb_scores = []\n",
    "\n",
    "fold = 1\n",
    "for train_index, test_index in skf.split(df['Query'], df['Label']):\n",
    "    print(f\"\\nðŸ§ª Fold {fold} -------------------------\")\n",
    "    train_df = df.iloc[train_index]\n",
    "    test_df = df.iloc[test_index]\n",
    "\n",
    "    # Convert to Hugging Face Dataset Format\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "    # Tokenization function\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"Query\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\"microsoft/codebert-base\", num_labels=2)\n",
    "\n",
    "    train_dataset = train_dataset.map(tokenize_function, batched=True).remove_columns([\"Query\"]).rename_column(\"Label\", \"labels\").with_format(\"torch\")\n",
    "    test_dataset = test_dataset.map(tokenize_function, batched=True).remove_columns([\"Query\"]).rename_column(\"Label\", \"labels\").with_format(\"torch\")\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results_fold_{fold}\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f\"./logs_fold_{fold}\",\n",
    "        load_best_model_at_end=False\n",
    "    )\n",
    "\n",
    "    def compute_metrics(pred):\n",
    "        logits, labels = pred\n",
    "        predictions = np.argmax(logits, axis=1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
    "        acc = accuracy_score(labels, predictions)\n",
    "        return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    y_true = predictions.label_ids\n",
    "    y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "    codebert_scores.append(evaluate_metrics_and_confusion(y_true, y_pred))\n",
    "\n",
    "    # ----- BERT Embeddings for DNN & XGBoost -----\n",
    "    bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def get_bert_embeddings(queries, batch_size=32):\n",
    "        embeddings = []\n",
    "        for i in tqdm(range(0, len(queries), batch_size), desc=\"Extracting BERT embeddings\"):\n",
    "            tokens = bert_tokenizer(queries[i:i+batch_size], return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "            with torch.no_grad():\n",
    "                outputs = bert_model(**tokens)\n",
    "            batch_embeddings = outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "            embeddings.append(batch_embeddings)\n",
    "        return np.vstack(embeddings)\n",
    "\n",
    "    train_embeddings = get_bert_embeddings(list(train_df['Query']))\n",
    "    test_embeddings = get_bert_embeddings(list(test_df['Query']))\n",
    "\n",
    "    # DNN\n",
    "    dnn_model = Sequential([\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    dnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "    dnn_model.fit(train_embeddings, train_df['Label'], epochs=5, batch_size=32, verbose=0)\n",
    "    y_pred_dnn = (dnn_model.predict(test_embeddings) > 0.5).astype(\"int32\")\n",
    "    dnn_scores.append(evaluate_metrics_and_confusion(test_df['Label'], y_pred_dnn))\n",
    "\n",
    "    # XGBoost\n",
    "    xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    xgb.fit(train_embeddings, train_df['Label'])\n",
    "    y_pred_xgb = xgb.predict(test_embeddings)\n",
    "    xgb_scores.append(evaluate_metrics_and_confusion(test_df['Label'], y_pred_xgb))\n",
    "\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž Average Results for CodeBERT\n",
      "Accuracy  : 0.9989\n",
      "Precision : 0.9992\n",
      "Recall    : 0.9979\n",
      "F1        : 0.9985\n",
      "\n",
      "ðŸ”Ž Average Results for DNN\n",
      "Accuracy  : 0.9977\n",
      "Precision : 0.9975\n",
      "Recall    : 0.9963\n",
      "F1        : 0.9969\n",
      "\n",
      "ðŸ”Ž Average Results for XGBoost\n",
      "Accuracy  : 0.9969\n",
      "Precision : 0.9971\n",
      "Recall    : 0.9944\n",
      "F1        : 0.9957\n"
     ]
    }
   ],
   "source": [
    "def print_average_scores(scores, model_name):\n",
    "    print(f\"\\nðŸ”Ž Average Results for {model_name}\")\n",
    "    for metric in [\"accuracy\", \"precision\", \"recall\", \"f1\"]:\n",
    "        avg = np.mean([fold[metric] for fold in scores])\n",
    "        print(f\"{metric.capitalize():<10}: {avg:.4f}\")\n",
    "\n",
    "print_average_scores(codebert_scores, \"CodeBERT\")\n",
    "print_average_scores(dnn_scores, \"DNN\")\n",
    "print_average_scores(xgb_scores, \"XGBoost\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
